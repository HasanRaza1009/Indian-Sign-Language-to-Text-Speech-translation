# Indian-Sign-Language-to-Text/Speech-translation

An AI-powered system that translates Indian Sign Language (ISL) gestures captured from a webcam into real-time text and speech. This project bridges the communication gap between the hearing and speech-impaired communities and the rest of the world.

---

## üöÄ Project Overview

This project uses computer vision and deep learning (CNN - MobileNetV2) to recognize hand gestures from Indian Sign Language (ISL) in real-time. It converts these gestures to text and then to speech using gTTS (Google Text-to-Speech). The system provides a user-friendly GUI built with Tkinter and supports multilingual translation.

---

---
## üé• Demo
[‚ñ∂Ô∏è Click here to watch the demo video](https://github.com/HasanRaza1009/Indian-Sign-Language-to-Text-Speech-translation/blob/main/sign_to_speech.mp4)
---

## üìå Features

- Real-time gesture recognition using MediaPipe  
- Deep learning model (MobileNetV2) for classification  
- Text-to-speech output using gTTS  
- Multilingual support with language selection  
- CLAHE-based image preprocessing for better model accuracy  
- User-friendly GUI interface using Tkinter  
- Organized module-based project structure  

---

## üß± Project Structure

```
Indian-Sign-Language-to-Text-Speech-translation/
‚îú‚îÄ‚îÄ capture.py               # GUI to capture gesture images using webcam
‚îú‚îÄ‚îÄ preprocess.py            # Preprocess captured images with CLAHE
‚îú‚îÄ‚îÄ model.py                 # Train MobileNetV2 CNN on processed data
‚îú‚îÄ‚îÄ recognise_sign.py        # Real-time translator: Sign ‚Üí Text ‚Üí Speech
‚îú‚îÄ‚îÄ requirements.txt         # Python dependencies
‚îú‚îÄ‚îÄ media/
‚îÇ   ‚îî‚îÄ‚îÄ demo.mp4             #demo video
‚îú‚îÄ‚îÄ README.md                # Project documentation
‚îú‚îÄ‚îÄ model/                   # Saved trained model files
‚îú‚îÄ‚îÄ dataset/                 # Captured and preprocessed gesture images
‚îÇ   ‚îú‚îÄ‚îÄ A/
‚îÇ   ‚îú‚îÄ‚îÄ B/
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ assets/                  # UI icons, reference images, etc.
```

---
---
## Dataset

The dataset used for training and testing is large, so it is hosted externally.

You can download the complete dataset ZIP file here:  
[Download Dataset (Dropbox)](https://www.dropbox.com/scl/fi/rogqgtx6myxkflxg6wb1e/dataset.zip?rlkey=uobxbnknwgrekbikchbro315h&st=qigcak5q&dl=0)
After downloading, unzip the folder into the `dataset/` directory of this project.

use this dataset as referenece, capture your own data at different time intervals so that the webcam gets adapted to the noise levels at different time intervals.
---

## üõ†Ô∏è Installation

### 1. Clone the repository:

```bash
git clone https://github.com/HasanRaza1009/Indian-Sign-Language-to-Text-Speech-translation.git
cd Indian-Sign-Language-to-Text-Speech-translation
```

### 2. Create and activate a virtual environment (recommended):

```bash
python -m venv venv

# On macOS/Linux
source venv/bin/activate

# On Windows
venv\Scripts\activate
```

### 3. Install required packages:

```bash
pip install -r requirements.txt
```

> ‚ö†Ô∏è Python version must be between 3.8 and 3.10 for compatibility.

---

## üì¶ Requirements

- Python 3.8 - 3.10  
- Webcam  
- Stable internet connection (needed for Google Text-to-Speech)  
- Packages listed in `requirements.txt`, including but not limited to:  
  - tensorflow==2.12.0  
  - opencv-python==4.7.0.72  
  - mediapipe==0.10.3  
  - numpy==1.24.3  
  - Pillow==9.5.0  
  - gTTS==2.3.2  
  - scikit-learn==1.2.2  
  - matplotlib==3.7.1  

> Tkinter comes pre-installed with Python.

---

## üì∏ Usage

### Step 1: Capture dataset images

```bash
python capture.py
```

- Use the GUI to record gesture images (alphabets, digits) through your webcam.

### Step 2: Preprocess dataset

```bash
python preprocess.py
```

- Applies CLAHE for contrast enhancement and resizes images to prepare for training.

### Step 3: Train the model

```bash
python model.py
```

- Trains MobileNetV2 CNN on your preprocessed images and saves the trained model.

### Step 4: Run real-time sign language translator

```bash
python recognise_sign.py
```

- Opens webcam and translates recognized ISL signs to text and speech in real-time.

---

## üåê Multilingual Support

- Select your preferred language in the GUI before running the translator.  
- Uses Google Text-to-Speech (gTTS) API to speak recognized text in the selected language (e.g., Hindi, Kannada, etc.).

---

## ‚úçÔ∏è Contributing

Contributions are welcome! To contribute:

- Fork the repo  
- Create a new branch:  
  ```bash
  git checkout -b feature/YourFeature
  ```
- Commit your changes:  
  ```bash
  git commit -m "Add YourFeature"
  ```
- Push the branch:  
  ```bash
  git push origin feature/YourFeature
  ```
- Open a Pull Request for review.

---

## üí° Future Enhancements

- Sentence prediction and grouping words for natural language output  
- Support for dynamic gesture recognition (moving signs)  
- Deployment as a mobile or web app for wider accessibility

---

